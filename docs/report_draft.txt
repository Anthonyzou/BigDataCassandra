Big Data Project Report 

Authors:    Shenwei Liao, Anthony Ou, Jacqueline Terlaan
Class:      CMPUT 391
Term:       Winter 2014

Section 0: Introduction to Cassandra 

    -What is NoSQL?
        -"Not Only SQL". But what does this mean?
            -Any database system which does not strictly conform to the
             relational database model. We may have any one of the following:
                -Does not meet all "ACID" properties.
                -May store data in a fashion other than a strictly
                 relational set of tables.

    -Why NoSQL?
        -We have some BIG data to deal with (several TB), and growing!
        -Big Data implies distribution;
        -Distribution implies CAP theorem;
        -CAP theorem implies compromises!

    -What is Apache Project's Cassandra?
        -NoSQL DBMS, meant to be highly scalable.
        -FOSS/FLOSS alternative to proprietary (and expensive) Oracle
         NoSQL systems.

        Features:
            -Available, Partition-tolerant
            -Eventually consistent
            -High scalability
            -"Schemaless" (implicit schema)
            -Has its own query language: Apache cql
            -Data compaction

    -Why Cassandra?
        -Partition-tolerant (essential for clustered systems).
        -Available: mirrors "real-world" constraints on call-detail record
         systems.
        -Eventual consistency is an acceptable compromise; we are not
         running a mission-critical system (like a bank), and most of our
         data insertion is similar to logging data.
        -Cassandra is especially well-suited to storing logs.
        -Widely used and relatively bug-free, especially for such "new" 
         software.
        -Handles map-reduce and low-level details of storage process for nodes,
         as well as performing maintenance (as specified by DB admin), such
         as compaction.
        -Very low chance of data loss (except if the DBA makes a mistake),
         even when upgrading Cassandra.

Section 1: Goals and Objectives
    -To successfully implement a distributed database system which will
     reliably store at least 16TB of random data consisting of random
     numeric and string-like data types organized into large tables with
     many columns (attributes).
    -To distribute the data in the above tables across 8 "nodes" (servers), 
     which form our "cluster".
    -To generate additional tables distributed throughout the cluster to
     be optimally configured for the queries to meet their own requirements
     (see below).
     
    -To query the above tables such that all of the following requirements
     are met by five queries.
        1) Four of five queries must retrieve data across from all of the
           distributed nodes.
        2) At least one of the queries must contain at least ten atomic
           conditions (formulas) in the WHERE clause.
        3) At least two of the queries must utilize both the GROUP BY and
           ORDER BY clauses. Since Cassandra does not yet support GROUP BY
           aggregation, the same functionality must be acheived in another
           way.
        4) At least three of the five queries must be range queries which
           specify an upper and lower bound on some ordered attribute that
           is used for the purposes of querying.
        5) None of the five queries can be trivial. That is, there can be
           no simple key searches or anything that is of little practical
           interest for measuring how a database system can deal with
           computationally expensive requests.

    -To record the execution time of each query.


Section 2: Methodology, Tools and Equipment Used
    -8 server instances, each with:
        -32GB virtual memory.
        -1TB secondary storage (hard-disk space) per node.
        

Section 3: Implementation

Subsection 3.1: Data Generation
    -Cluster name: 'group3'
        -Only nodes with this name can join the cluser.

    -Shell script
        -To run: sh group3.sh
        -Set up to be able to run multiple instances and then send the output
         to an output file.
        -To generate data: follow the prompts by entering option numbers.

    -Table schema
        -"CDR"
            -Exactly 100 columns.
            -Numbers range from 0 to 9.9 million for all integers.
            -Has 10 column keys and 1 partition key.
        -"QUERY3"
            -Contains the same data, but the column keys are ordered MSC_CODE first in
             an attempt to optimize for range-queries based on values of those column keys.
        -"GROUP_BY_MONTH" 
            -Keys are between 1 and 31.
            -Reduces data to facilitate completion of a query equivalent to one
             in SQL containing 'GROUP BY MONTH_DAY'.
            -Uses 'WITH CLUSTERING ORDER BY(MONTH_DAY)' to facilitate ordering the resulting
             tables contents by the day of the month.
        -"GOUP_BY_MOBILE_ID_TYPE"
            -Keys are between 0 and 7.
            -Similar to "GROUP_BY_MONTH", but instead the assignment of the rows' locations
             is based on its insertion number modulo 8.
            -'CLUSTERING ORDER BY(MOBILE_ID_TYPE)' used to order the rows with respect to
             MOBILE_ID_TYPE instead of the aggregate group MONTH.
        -The role of the last two tables is to make the substitute aggregate queries both
         possible (as Cassandra has no explicit support for GROUP BY aggregation) 
         and efficient (pre-processing data to be optimal for queries).

    -Keyspaces
        -One keyspace used, with a 'SimpleStrategy' class and replication_factor of 1.
            -No backups or snapshots are automatically made by the server.

    -Python 2.7 scripts
        -generate.py
            -Begins with attempting to establish a connection to the local machine which is part
             of the cluster.
            -Expects program arguments: 
                -The number of days to generate data for. 
                -Different seed values to prevent collisions of data insertions.
                    -Cassandra has no support for primary keys; collisions result in overwriting data.
                    -Allows for multiple concurrent instances of data generation.
                -Without seed argument, the script will use its default seed value (typically used
                 for consistency in generation of data) and will drop all of the data before completely
                 regenerating it.
                -Depending on the results from stat.py (see below), 
            -Asynchronously executes the insertion statements to prevent blocking on the script.
            -generate() function
                -Allows for custom ranges on specified columns.
                -Allows for custom data for specified data types.

        -stat.py (mainly for testing)
            -Reads in the contents of "partial_data_table.txt" and "cdr_table.txt", then 
             counts the number of non-empty columns for each row.
            -Prints the resulting number (frequency) of items for each column.



Subsection 3.2: CQL Queries

    1)
SELECT count (*) as ten_atomic
FROM cdr 
WHERE 
(CITY_ID,SERVICE_NODE_ID,RUM_DATA_NUM,MONTH_DAY,DUP_SEQ_NUM,MOBILE_ID_TYPE,SEIZ_CELL_NUM,FLOW_DATA_INC,SUB_HOME_INT_PRI,CON_OHM_NUM) 
> (10000,10000,10000,3,10000,1,10000,10000,10000,10000)
AND (CITY_ID,SERVICE_NODE_ID,RUM_DATA_NUM,MONTH_DAY,DUP_SEQ_NUM,MOBILE_ID_TYPE,SEIZ_CELL_NUM,FLOW_DATA_INC,SUB_HOME_INT_PRI,CON_OHM_NUM) 
< (150000,150000,150000,30,150000,8,150000,150000,150000,150000)
LIMIT 40000000
ALLOW FILTERING;

           Cluster-wide range query with 10 atomic formulas. Searches on every column key of the
           CDR table, as this is the only conceivable way to properly execute a range query.
           Returns results from each node, satisfies the range query requirement and has 10 atomic
           formulas.

           Potential uses: many 'outliers' are eliminated from the selection because they are above
           and below the minimum and maximum values of all the columns respectively, by approximately
           10%. In other words, any 'extreme' data points in the CDR table can be ignored for
           statistical analysis.

        2)
SELECT count (*) as range_city_id
FROM cdr
WHERE
CITY_ID > 5000 AND CITY_ID < 90000
LIMIT 40000000
ALLOW FILTERING;

           Satisfies two requirements: cluster-wide and range query. Retrieves the number of
           cdr entries for cities with IDs strictly greater than 5000 and strictly less than
           90000. Limits the maximal number of elements counted to 40000000. Filtering of
           results is enabled.

           Potential uses: In some cases companies may wish to know how many calls were made
           in a given range of cities, based on certain CITY_IDs. While those cities may not
           have any major features in common, this query can be used in cases where only a small
           sample of all cities is required.

        3) 
SELECT count(*) as range_DUP_SEQ_NUM
FROM cdr
WHERE 
(CITY_ID,SERVICE_NODE_ID,RUM_DATA_NUM,MONTH_DAY,DUP_SEQ_NUM)
>(0,0,0,0,30000) AND
(CITY_ID,SERVICE_NODE_ID,RUM_DATA_NUM,MONTH_DAY,DUP_SEQ_NUM)
<(9900000,9900000,9900000,9900000,300000)
LIMIT 40000000
ALLOW FILTERING;

           Satsifies two requirements: cluster-wide and range query. Counts the number of cdr
           entries such that DUP_SEQ_NUM is strictly greater than 30000 and strictly less than
           300000. All other atomic conditions in the range query are used to ensure that
           all of the results fall within a valid range and have no null-valued entries for
           CITY_ID, SERVICE_NODE_ID, and so on. Because we are trying to query mainly by 
           DUP_SEQ_NUM, we allow filtering on the query in order to speed up execution.

           Potential uses: Suppose that statistical data is to be generated for rows in the
           CDR table for which there are no null-valued entries in the columns CITY_ID,
           SERVICE_NODE_ID, RUM_DATA_NUM, MONTH_DAY and DUP_SEQ_NUM, and that DUP_SEQ_NUM
           falls within a more specific range, that is 30000-300000 (not inclusive). The
           records could then be analyzed and compared to data for which not all of the
           attributes above are null, to compare behaviors of callers with different amounts
           of privacy. This could address questions such as "do people with more privacy make
           certain types of calls compared to people who do not?".

        4)
SELECT MOBILE_ID_TYPE,count
from GROUP_BY_MOBILE_ID_TYPE;

           Satisfies two requirements: group-by + order-by clause, and cluster-wide query.

           A table of counters aggregates the keys of the MOBILE_ID_TYPE columns with the 
           count of each number of rows in the CDR table with matchine MOBILE_ID_TYPE.
           Ordering by mobile_id_type is acheived by using a the 'USE CLUSTERING ORDER' 
           clause in the data definition statement in generate.py.
           We then retrieve GROUP_BY_MOBILE_ID_TYPEs contents and the count of its rows
           in order of appearance, i.e., the order in which the aggregated rows are sorted.

           MOBILE_ID is the insertion number modulo 8 (or however many nodes), therefore
           the rows of the MOBILE_ID table are evenly distributed throughout the cluster.
           This means that we can easily use this query as a check for correctness of
           the insertion process, as counting the number of rows in the MOBILE_ID_TYPE table
           on each node should total up to the number of unique items in the database.

           This is an atomic, yet seemingly asynchronous transaction. In other words, only
           small critical sections of execution are protected for short amounts of time
           to prevent collisions, but otherwise parallelism is fully exploited (with minimal
           constraints of Ahmdal's Law) due to the very even distribution of data across all 
           8 nodes. 

           Updating counter columns is done in the following way:

update group_by_MOBILE_ID_TYPE set count = count + 1  where MOBILE_ID_TYPE = ? and id = 1;

           Potential uses: Most likely for the generation of histograms, but other basic
           kinds of statistical analysis can be performed on these small MOBILE_ID_TYPE 
           'buckets' as well, such as calculating arithmetic averages, etc.

        5) 
SELECT month_day, count FROM group_by_month;

           Satisfies the group-by + order-by clause requirements. 
           'CLUSTERING ORDER BY (MONTH_DAY)' ensures that the GROUP_BY_MONTHs entries are ordered
           by MONTH_DAY, and GROUP BY functionality is acheived via aggregating the COUNT type
           column 'COUNTER' into MONTH_DAY groupings. The resulting COUNTER column typically
           contains values which are quite close in value, but with some differences between
           them due to the pseudorandom generation and distribution of data.

           Potential uses: finding out which day(s) of each month of the year have the highest
           frequency of entries added to the CDR table can be of use for marketing to customers,
           optimizing billing rates, and so on. Similar queries can be written for different
           times of the day, months or weeks of the year, by aggregating CDR row counts into 
           hourly, monthly or weekly groupings for more specific results which could be of use 
           in billing plans with calls at different times incurring different costs.

Section 4: Theoretical Description
    -Obviously, we are going to be constrained by the results of the CAP theorem.
    -As explained above, Cassandra is high-availability, partition-tolerant
     and eventually-consistent.
    
    -To get the equivalent of a GROUP BY aggregation:
        -Recall: a GROUP BY aggregation is basically a function which
         gathers rows of data retrieved by a query and 'clusters' them
         together based on the attribute that we are grouping by.

        -Suppose we have a table T on which we have columns C1,...,Cn,
         with rows R1,...,Rm. Say that P(C1) is an atomic formula which
         is satisfied for some C1 columns in R1,...,Rm.

            SELECT Ci, C1
            FROM T
            WHERE P(C1)
            GROUP BY Ci;    -- Where 1 <= i <= n

        -The above query will return something like this: (where 1 <= j <= k <= m)

        [TODO: Make a better illustration, but use LaTeX to do it]
            
            |  Ci  |  C1  |
            +------+------+
            |Rj.Ci |Rj.C1 |
            |  .   |  .   |
            |  .   |  .   |
            |  .   |  .   |
            |Rk.Ci |Rk.C1 |
            +------+------+


Section 5: Preliminary Test Results

    -Execution time for the data definition and data manipulation on the
     test-sized cluster (~1.75 TB).

        -Insertion of data for the first test query: 
            -Amount of data written: 300k entries. 
            -Time taken: approximately 35 minutes.

        -The amount of time required to complete the creation of the table 
         and insertion of data into that table for the first query took as long
         as it did for two main reasons:
            1) In traditional relational database systems aggregate functions
               such as the 'GROUP BY' clause are explicitly supported.
               While Cassandra does support certain aggregation clauses, such
               as 'ORDER BY', there is no explicit 'GROUP BY' function supported
               for use in (search) queries. Because of this, tables must be 
               created with aggregation done beforehand.
               Hence, anything that could be considered 'overhead' as a result of
               using a GROUP BY clause in a traditional relational database query
               is incurred in the generation and population of data tables in
               Cassandra. Hence, it took longer to insert data as Cassandra was
               essentially used to 'pre-proccess'/'pre-aggregate' it on insertion,
               as opposed to performing the equivalent aggregation during the
               execution of search queries where GROUP BY is desired.

               However, it is much faster.

            2) Counter tables were also required.

    -Execution times for queries on the test-sized cluster.


Section 6: Experimental Results
    -Execution time for the data definition and data manipulation on the
     fully populated cluster (~8 TB):


    -Execution time for queries on the fully populated cluster:


Section 7: Analysis and Discussion

    -Quantitative results: [Insert clean, organized tables in this section]

    -Quantitative analysis of results:
        -Most expensive query.
        -Query with most results.
        -Does this agree with a time-complexity analysis(?)
        -The amount of time it takes to retrieve all of the data in the cluster
         is very close to the amount of time it takes to insert all of the data
         into the entire cluster.

    -Qualitative description of results:
        -Insertion of data into nodes has a lower bound of the maximal write
         speed of secondary storage, in this case hard-disk.
        -Ahmdal's Law
            -Maximum gains from parallelism come when there is the most even
             distribution of work.
            -Parallelism 'deteriorates' in efficiency when distribution is
             very uneven.
            -Maximal speedup is always a strict upper bound of 1/N.
        -Impact of Cassandra's lack of collision management:
            -Many rows originally entered were overwritten with new rows, even 
             given the pseudo-random generation of primary key elements.
            -This may be due to: 
                -Problems with pseudorandom number generation in Python 2.7
                 which result in potentially biased distribution of numbers.
                -Avoiding the use of lexical or time-based UUIDs as part of
                 the primary key of the main CDR table in favour of faster
                 data definition, manipulation and querying. UUIDs may have
                 increased the uniqueness of each primary key and protected
                 more rows from being overwritten in the case of collisions.

Section 8: Conclusions


Section 9: Notes on Possible Improvements

    -For increased table population time efficiency:
        -

    -For increased query execution time efficiency:
        -Increasing the number of smaller tables...? More data tables for the same
         data set but with fewer columns in each to make optimizing for queries easier(?)
        -

    -For increased data protection:
        -Potential use of UUIDs to increase uniqueness of primary keys so as
         to dramatically decrease the odds of collisions.
            -Comes with a computational cost for queries and especially for data definition
             and modification. Generating one 128-bit UUID is not expensive in and of
             itself, but multiplying that operation upward of one trillion times will
             incur a greater cost compared to going without, or generating something
             in constant time.

        -Use of a higer replication factor. In our case, we discovered that using
         replication factor of 3 helped with 'protecting' data.

Section 10: References Used

Agilent Technologies Inc (28 October, 2014), "Mobile Station Reported Pilot Information".
    Available at: http://wireless.agilent.com/rfcomms/refdocs/cdma2k/c2kla_gen_ms_pilot_meas_report.html
    Accessed: 10 March 2014.


Apache Software Foundation (2004), "The Apache Licence, Version 2.0".
    Available at: http://www.apache.org/licences/LICENCE-2.0
    Accessed 7 March, 2014.

Apache Software Foundation (10 March 2014), "Cassandra Query Language (CQL) v3.1.5".
    Available at: http://cassandra.apache.org/doc/cql3/CQL.html
    Accessed: 10 March 2014.

Apache Software Foundation (15 November 2013), "UUID".
    Available at: http://wiki.apache.org/cassandra/UUID
    Accessed: 13 March 2014.


DataStax Documentation (2014), "Cassandra Storage Basics".
    Available at: http://www.datastax.com/documentation/cassandra/2.0/cassandra/dml/manage_dml_intro_c.html
    Accessed 7 March, 2014.

DataStax Documentation (2014), "The cassandra.yaml Configuration File".
    Available at: http://www.datastax.com/documentation/cassandra/2.0/cassandra/configuration/configCassandra_yaml_r.html 
    Accessed 7 March, 2014.  

DataStax Documentation (2014), "CLI keyspace and table storage configuration".
    Available at: http://www.datastax.com/documentation/cassandra/2.0/cassandra/reference/referenceStorage_r.html
    Accessed: 10 March 2014.

DataStax Inc. (2014), "UUID and timeuuid".
    Available at: http://www.datastax.com/documentation/cql/3.0/cql/cql_reference/uuid_type_r.html
    Accessed: 13 March 2014.

DataStax Documentation (2014), "What's new in Cassandra 2.0".
    Available at: http://www.datastax.com/documentation/cassandra/2.0/cassandra/features/features_key_c.html
    Accessed: 10 March 2014.

DataStax Documentation (2014), "The Write Path to Compaction".
    Available at: http://www.datastax.com/documentation/cassandra/2.0/cassandra/dml/dml_write_path_c.html
    Accessed 7 March, 2014.


Fowler, M. (9 January 2012), "NosqlDefinition".
    Available at: http://martinfowler.com/bliki/NosqlDefinition.html
    Accessed: 13 March 2014.

Fowler, M. (16 November 2011), "PolyglotPersistence".
    Available at: http://martinfowler.com/bliki/PolyglotPersistence.html
    Accessed: 13 March 2014.

Fowler, M. (7 January 2013), "Schemaless Data Structures".
    Available at: http://martinfowler.com/tags/noSQL.html
    Accessed: 14 March 2014.


Grinev, M. (9 July 2010), "A Quick Introduction to the Cassandra Data Model".
    Available at: http://maxgrinev.com/2010/07/09/a-quick-introduction-to-the-cassandra-data-model/
    Accessed: 10 March 2014.

Grinev, M. (12 July 2010), "Do You Really Need SQL to Do It All in Cassandra?".
    Available at:  http://maxgrinev.com/2010/07/12/do-you-really-need-sql-to-do-it-all-in-cassandra/
    Accessed: 10 March 2014.


McFadin, P. (13 November 2012), "Cassandra Data Modeling Talk".
    Available at: http://www.slideshare.net/patrickmcfadin/data-modeling-talk
    Accessed: 13 March 2014.

McFadin, P. (3 May 2013), "The Data Model is Dead, Long Live the Data Model!".
    Available at: http://www.slideshare.net/patrickmcfadin/the-data-model-is-dead-long-live-the-data-model
    Accessed: 14 March 2014.

McFadin, P. (16 May 2013), "Become a Super Modeler".
    Available at: http://www.slideshare.net/patrickmcfadin/become-a-super-modeler
    Accessed: 14 March 2014.

McFadin, P. (24 June 2013), "The World's Next Top Data Model".
    Available at: http://www.slideshare.net/patrickmcfadin/the-worlds-next-top-data-model
    Accessed: 14 March 2014.

McFadin, P. (11 October 2013), "Cassandra 2.0: Better, Stronger Faster".
    Available at: http://blog.imaginea.com/consistency-tuning-in-cassandra/
    Accessed: 14 March 2014.

McFadin, P. (17 February 2014), "Time Series with Apache Cassandra".
    Available at: http://www.slideshare.net/patrickmcfadin/time-series-with-apache-cassandra-strata
    Accessed: 13 March 2014.


Oracle Inc. (Copyright 1996-2005), "Datatype Comparison Rules".
    Available at: http://docs.oracle.com/cd/B19306_01/server.102/b14200/sql_elements002.htm#i55214
    Accessed: 10 March 2014.

Oracle Inc (No date), "GROUP BY clause".
    Available at: http://docs.oracle.com/javadb/10.6.1.0/ref/rrefsqlj32654.html
    Accessed 7 March, 2014.

Oracle Inc (No date), "ORDER BY clause".
    Available at: http://docs.oracle.com/javadb/10.6.1.0/ref/rrefsqlj13658.html
    Accessed: 10 March 2014.

Oracle Inc (No date), "SelectExpression".
    Available at: http://docs.oracle.com/javadb/10.6.1.0/ref/rrefselectexpression.html#rrefselectexpression
    Accessed: 10 March 2014.

Oracle Inc. (Copyright 1996-2005), "SYSDATE".
    Available at: http://docs.oracle.com/cd/B19306_01/server.102/b14200/functions172.htm
    Accessed: 10 March 2014.

Oracle Inc. (Copyright 1996-2005), "SYSTIMESTAMP".
    Available at: http://docs.oracle.com/cd/B19306_01/server.102/b14200/functions173.htm
    Accessed: 10 March 2014.

Oracle Inc. (Copyright 1996-2005), "TO_DATE".
    Available at: http://docs.oracle.com/cd/B19306_01/server.102/b14200/functions183.htm
    Accessed: 10 March 2014.


Saxena, S. (4 September 2013), "Consistency Tuning In Cassandra".
    Available at: http://blog.imaginea.com/consistency-tuning-in-cassandra/
    Accessed: 14 March 2014.


