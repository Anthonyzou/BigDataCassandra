Big Data Project Report 

Authors:    Shenwei Liao, Anthony Ou, Jacqueline Terlaan
Class:      CMPUT 391
Term:       Winter 2014

Section 0: Introduction to Cassandra 
    -What is "Big Data" (and why should people care)?
        -Example(s): Reddit comment system organization.
            -We have easily millions of comments generated. Each one has
             an author, text string, community rating, number of upvotes
             and downvotes, which thread it is in, when it was posted,
             if and when it was edited, etc.
            -How do we store them all such that we can both update them
             when they are added, edited, deleted, 'upvoted'/'downvoted',
             marked as 'gold', flagged, or even whether they contain
             certain phrases of interest, and so on?
        -How would we best implement this?
            -Many TB of information and it must be queried and manipulated 
             "on the fly"!
            -Although, we don't have too many types of queries...
            -Naive solution: use one monolithic server with an oversized
             storage capability.
                -We have just increased our risk of colossal system failure!
                -Might need its own special custom architecture:
                    -Expensive.
                    -Hard to maintain, not standard/highly specialized.
                    -Maintenance could cause the entire system to go down
                     temporarily, or even permanently (see first point).
                -Might be way too big to even exist!
                    -Even a large server has an "upper bound" on its size. 
                        -For example, where will it get its power from?
                         It is possible to have a server that has such a 
                         high a power requirement that it would be totally
                         infeasible to build because it would need a huge
                         power-plant to feed it.
                -Could be slow.
                    -Processing power might not grow as fast as storage size.
            -Better solution: use multiple smaller servers.
                -Easier to maintain.
                -If one node fails, it is unlikely to cause system-wide
                 failure if all servers are connected (dense graph).
                    -Corollary: We can do 'rotational' maintenance on servers.
                -Less need for highly specialized architecture, except for
                 wanting something that is efficient for servers.
                -Given high-speed network connections and higher signal
                 bandwidth, we can have separate data-centers.
                    -Across the building...
                    -Across the street...
                    -Across the city...
                    -Across the country/world!

            -However: this introduces the need for a NoSQL alternative.

    -What is NoSQL?
        -"Not Only SQL". But what does this mean?
            -Any database system which does not strictly conform to the
             relational database model. We may have any one of the following:
                -Does not meet all "ACID" properties.
                    -Atomicity - Operations on the database are either 
                                 completely committed or discarded. 
                                 There are no "partially completed"
                                 transactions.
                    -Consistency - If two fields are to store the same value
                                   at all times, this will never change.
                                   i.e., there are no violations on foreign 
                                   key constraints.
                    -Isolation - No two transactions will affect each others'
                                 outcome, no matter which order they are
                                 scheduled in, and no two transactions can
                                 interfere with each others ability to
                                 be completed if they are requested within
                                 a very short time-interval.
                                 i.e., there will be no race-conditions,
                                 deadlocks or starving.
                    -Durability - All data-definition and data-manipulation
                                  transactions are permanent and irreversible
                                  once they are committed. 
                -May store data in a fashion other than a strictly
                 relational set of tables.
                    -Old example: the "network" model. Widely used before
                     Edgar Codd's implementation of relational databases.
                    -Newer examples:
                        -

    -Why NoSQL?
        -We have some BIG data to deal with (several TB), and growing!
        -Big Data implies distribution;
        -Distribution implies CAP theorem;
        -CAP theorem implies compromises!

    -What is Apache Project's Cassandra? [Most important section]
        -NoSQL DBMS, meant to be highly scalable.
        -FOSS/FLOSS alternative to proprietary (and expensive) Oracle
         NoSQL systems.

        Features:
            -Available, Partition-tolerant
            -Eventually consistent
            -High scalability!
            -"Schemaless" (implicit schema)
            -Has its own query language: Apache cql
            -Data compaction
        -

    -Why Cassandra? [Most important section]
        -Partition-tolerant (essential for clustered systems).
        -Available: mirrors "real-world" constraints on call-detail record
         systems.
        -Eventual consistency is an acceptable compromise; we are not
         running a mission-critical system (like a bank), and most of our
         data insertion is similar to logging data.
        -Cassandra is especially well-suited to storing logs.
        -Widely used and relatively bug-free, especially for such "new" 
         software.
        -Handles map-reduce and low-level details of storage process for nodes,
         as well as performing maintenance (as specified by DB admin), such
         as compaction.
        -Very low chance of data loss (except if the DBA makes a mistake),
         even when upgrading Cassandra.

        -Other Niceties:
            -FOSS/FLOSS compliant ("libre"); see also: the Apache Licence.
            -No monetary cost ("gratis").
            -Relatively easy to use!

    -Why Not Use Cassandra Everywhere?
        -Eventual consistency, so not suited to mission-critical applications.
        -Can lose efficiency over time if you do not perform regular
         maintenance such as compaction.
        -You have to design your DB schema around your queries, which is
         the opposite of the traditional process.
        -Impossible to implement aggregation after your tables have been
         generated, which is a consequence of the above.
        -Might not be as efficient or polished as an Oracle Inc. alternative.
         If you have the money, this might be the best option for you.
        -NoSQL systems require some experience with relational SQL systems,
         as they have a SQL-like interface and behavior, the are still
         declarative, and are usually less well-documented and
         "beginner-friendly" as the older SQL systems.

    -What is the Apache Project? [Optional]

Section 1: Goals and Objectives
    -To successfully implement a distributed database system which will
     reliably store at least 16TB of random data consisting of random
     numeric and string-like data types organized into large tables with
     many columns (attributes).
    -To distribute the data in the above tables across 8 "nodes" (servers), 
     which form our "cluster".
    -To generate additional tables distributed throughout the cluster to
     be optimally configured for the queries to meet their own requirements
     (see below).
     
    -To query the above tables such that all of the following requirements
     are met by five queries.
        1) Four of five queries must retrieve data across from all of the
           distributed nodes.
        2) At least one of the queries must contain at least ten atomic
           conditions (formulas) in the WHERE clause.
        3) At least two of the queries must utilize both the GROUP BY and
           ORDER BY clauses. Since Cassandra does not yet support GROUP BY
           aggregation, the same functionality must be acheived in another
           way.
        4) At least three of the five queries must be range queries which
           specify an upper and lower bound on some ordered attribute that
           is used for the purposes of querying.
        5) None of the five queries can be trivial. That is, there can be
           no simple key searches or anything that is of little practical
           interest for measuring how a database system can deal with
           challenging or expensive requests.

    -To record the execution time of each query.

Section 2: Methodology, Tools and Equipment Used
    -8 server instances, each with:
        -4CPU cores, (Intel) x86_64 architecture, 1 thread/core, 1999 MHz.
        -32GB main memory.
        -4TB secondary storage (hard-disk space).
        -GNU/Linux (Ubuntu) version ???
        
    -This gives us a total upper bound on storage of 32TB over the entire
     cluster.


Section 3: Theoretical Description
    -Obviously, we are going to be "using" the CAP theorem.
    -As explained above, Cassandra is high-availability, partition-tolerant
     and eventually consistent.
    
    -To get the equivalent of a GROUP BY aggregation:
        -Recall: a GROUP BY aggregation is basically a function which
         gathers rows of data retrieved by a query and 'clusters' them
         together based on the attribute that we are grouping by.

        -Suppose we have a table T on which we have columns C1,...,Cn,
         with rows R1,...,Rm. Say that P(C1) is an atomic formula which
         is satisfied for some C1 columns in R1,...,Rm.

            SELECT C1, Ci
            FROM T
            WHERE P(C1)
            GROUP BY Ci;    -- Where 1 <= i <= n

        -The above query will return something like this:
            
            |   C1  |   Ci  |
            +-------+-------+

Section 4: Test Results
    -Insertion of data for the first test query: 
        -Amount of data written: 300k entries. 
        -Time taken: approximately 35 minutes.

    -The amount of time required to complete the creation of the table 
     and insertion of data into that table for the first query took as long
     as it did for two main reasons:
        1) In traditional relational database systems aggregate functions
           such as the 'GROUP BY' clause are explicitly supported.
           While Cassandra does support certain aggregation clauses, such
           as 'ORDER BY', there is no explicit 'GROUP BY' function supported
           for use in (search) queries. Because of this, tables must be 
           created with aggregation done beforehand.
           Hence, anything that could be considered 'overhead' as a result of
           using a GROUP BY clause in a traditional relational database query
           is incurred in the generation and population of data tables in
           Cassandra. Hence, it took longer to insert data as Cassandra was
           essentially used to 'pre-proccess'/'pre-aggregate' it on insertion,
           as opposed to performing the equivalent aggregation during the
           execution of search queries where GROUP BY is desired.
        2) Counter tables were also required. [LINEAR TIME?]

Section 5: Experimental Results

Section 6: Conclusions

Section 7: Notes on Possible Improvements

Section 8: References Used

Section 9: Illustration Credits

Section 10: Special Thanks [Where should this go?]
    -We would like to thank: 
        -Cybera for allowing us to use their servers.
        -Dr. Yuan (University of Alberta) for the project idea.
        -Lengdong Wu (University of Alberta) for help along the way.
